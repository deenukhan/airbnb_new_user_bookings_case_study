{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking_model_1.ipynb",
      "provenance": [],
      "mount_file_id": "1r9e7GX01p1a_W5h_FnkkFBEF-SDo0Seq",
      "authorship_tag": "ABX9TyPKO1onaKbaDGWI5+TtaZCK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deenukhan/airbnb_new_user_bookings_case_study/blob/main/stacking_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Iz_l4aMNkD"
      },
      "source": [
        "## About Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4z9CC1xMVtP"
      },
      "source": [
        "<p>In this challenge, you are given a list of users along with their demographics, web session records, and some summary statistics. You are asked to predict which country a new user's first booking destination will be.&nbsp;All the users in this dataset are from&nbsp;the USA.</p>\n",
        "\n",
        "<p>There are 12 possible outcomes of the destination country:&nbsp;'US', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL','DE', 'AU', 'NDF' (no destination found), and&nbsp;'other'. Please note that 'NDF' is different from 'other' because 'other' means there was a booking, but is to a country not included in the list, while 'NDF' means there wasn't a booking.</p>\n",
        "\n",
        "<p>The training and test sets are split by dates. In the test set, you will predict all the new users with first activities after <strong>7/1/2014 (note: this is updated on 12/5/15 when the competition restarted)</strong>.&nbsp;In the sessions dataset, the data only dates back to 1/1/2014, while the users dataset dates back to 2010.&nbsp;</p>\n",
        "\n",
        "<h3>Data Files descriptions</h3>\n",
        "<ul>\n",
        "<li><strong>train_users.csv</strong>&nbsp;- the training set of users</li>\n",
        "<li><strong>test_users.csv</strong> - the test set of users</li>\n",
        "<ul>\n",
        "<li>id: user id</li>\n",
        "<li>date_account_created: the date of account creation</li>\n",
        "<li>timestamp_first_active: timestamp of the first activity, note that it can be earlier than&nbsp;date_account_created or&nbsp;date_first_booking because a user can search before signing up</li>\n",
        "<li>date_first_booking: date of first booking</li>\n",
        "<li>gender</li>\n",
        "<li>age</li>\n",
        "<li>signup_method</li>\n",
        "<li>signup_flow:&nbsp;the page a user came to signup up from</li>\n",
        "<li>language: international language preference</li>\n",
        "<li>affiliate_channel:&nbsp;what kind of paid marketing</li>\n",
        "<li>affiliate_provider:&nbsp;where the marketing is e.g. google, craigslist, other</li>\n",
        "<li>first_affiliate_tracked:&nbsp;whats the first marketing the user interacted with before the signing up</li>\n",
        "<li>signup_app</li>\n",
        "<li>first_device_type</li>\n",
        "<li>first_browser</li>\n",
        "<li>country_destination: this is the <strong>target variable</strong> you are to predict</li>\n",
        "</ul>\n",
        "<li><strong>sessions.csv</strong> -&nbsp;web sessions log for users</li>\n",
        "<ul>\n",
        "<li>user_id: to be joined with the column 'id' in users table</li>\n",
        "<li>action</li>\n",
        "<li>action_type</li>\n",
        "<li>action_detail</li>\n",
        "<li>device_type</li>\n",
        "<li>secs_elapsed</li>\n",
        "</ul>\n",
        "<li><strong>countries.csv&nbsp;</strong>- summary statistics of destination countries in this dataset and their locations</li>\n",
        "<li><strong>age_gender_bkts.csv</strong> - summary statistics of users' age group, gender, country of destination</li>\n",
        "<li><strong>sample_submission.csv</strong> -&nbsp;correct format for submitting your predictions</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bNZfTVCI0yy"
      },
      "source": [
        "## Extracting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suG7Amg63mAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9632d24d-92d9-46bb-877d-419261376b0c"
      },
      "source": [
        "#Below code is just to copy all the files into current session's drive and creating and deleting few required folders\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "!mkdir airbnb_data\n",
        "!mkdir temp\n",
        "!cp \"/content/drive/My Drive/Study/Case Study 1/airbnb_data/airbnb_data.zip\" /content/\n",
        "\n",
        "#-q is oppsoite of verbose, -d for decompressing to directory\n",
        "!unzip -q /content/airbnb_data.zip -d /content/temp/\n",
        "\n",
        "for zip_files in tqdm(os.listdir('/content/temp')):\n",
        "    path = os.path.join(\"/content/temp\", zip_files)\n",
        "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content/airbnb_data\")\n",
        "    os.remove(path)\n",
        "\n",
        "os.remove(\"/content/airbnb_data.zip\")\n",
        "os.rmdir(\"/content/temp\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl2GRq_Vh_ny"
      },
      "source": [
        "## Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEx6AMHVCe7U"
      },
      "source": [
        "#Importing Libraries\n",
        "#Importing Libraries\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#Base Learners\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4yhdd2Gh9bY"
      },
      "source": [
        "#Reading the data\n",
        "age_gender = pd.read_csv('/content/airbnb_data/age_gender_bkts.csv')\n",
        "countries = pd.read_csv('/content/airbnb_data/countries.csv')\n",
        "sessions = pd.read_csv('/content/airbnb_data/sessions.csv')\n",
        "train_users = pd.read_csv('/content/airbnb_data/train_users_2.csv')\n",
        "test_users = pd.read_csv('/content/airbnb_data/test_users.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi4PmVxodXYw"
      },
      "source": [
        "## Data Perpartation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrf01A-uNiL7"
      },
      "source": [
        "'''First Let's combine both the dataset, train and test and then perform all data preproccesing steps and Encodings.\r\n",
        "   I beleive this would cause data leakage Problem, but as we are solving kaggle compettion, I need to focus more \r\n",
        "   on getting highest score, Please suggest if i should not do such thing ? '''\r\n",
        "\r\n",
        "train_test = pd.concat(((train_users.drop(['id', 'country_destination', 'date_first_booking'], axis= 1)), \r\n",
        "                             (test_users.drop(['id', 'date_first_booking'], axis= 1))), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe_g_bXyN4nQ"
      },
      "source": [
        "'''For the First Try, I have taken everthing simple, no complex impuations, all just straight forward.\r\n",
        "   Going ahead we'll try more advance approached for imputations.\r\n",
        "   Here I am just, Imputing Null values and dealing with some unwanted values in columns'''\r\n",
        "\r\n",
        "#creating object of SimpleImputer\r\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\r\n",
        "imputer_num = SimpleImputer()\r\n",
        "\r\n",
        "#First doing some data cleaning\r\n",
        "train_test['gender'].replace({'-unknown-':np.nan}, inplace = True)\r\n",
        "train_test['first_browser'].replace({'-unknown-':np.nan}, inplace = True)\r\n",
        "train_test['age'] = train_test['age'].apply(lambda age : np.nan if (age > 90 or age<18) else age)\r\n",
        "\r\n",
        "#Doing Imputation of gender, first_browser, first_affiliate_tracked, age\r\n",
        "train_test['gender'] = imputer_cat.fit_transform(train_test['gender'].values.reshape(-1, 1))\r\n",
        "train_test['first_browser'] = imputer_cat.fit_transform(train_test['first_browser'].values.reshape(-1, 1))\r\n",
        "train_test['first_affiliate_tracked'] = imputer_cat.fit_transform(train_test['first_affiliate_tracked'].values.reshape(-1, 1))\r\n",
        "train_test['age'] = imputer_num.fit_transform(train_test['age'].values.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOaEV0kSN4kO"
      },
      "source": [
        "'''First we will be using date_account_created feature only, for that also we will create\r\n",
        "   3 new features dac_day, dac_month, dac_year.'''\r\n",
        "\r\n",
        "#First Converting feature into datetime object and then creating other features\r\n",
        "train_test['date_account_created'] = pd.to_datetime(train_test['date_account_created'])\r\n",
        "train_test['dac_day'] =  train_test['date_account_created'].apply(lambda date : date.day)\r\n",
        "train_test['dac_month'] =  train_test['date_account_created'].apply(lambda date : date.month)\r\n",
        "train_test['dac_year'] =  train_test['date_account_created'].apply(lambda date : date.year)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mHCLosEN4g1"
      },
      "source": [
        "''' For now i will work only with these features just for simplicity, and later will increase complexity gradually\r\n",
        "        'dac_day', 'dac_month', 'dac_year', 'signup_flow', 'age', \r\n",
        "        'signup_method', 'gender',\r\n",
        "        'language', 'affiliate_channel', 'affiliate_provider',\r\n",
        "        'first_affiliate_tracked', 'signup_app', 'first_device_type',\r\n",
        "        'first_browser' '''\r\n",
        "\r\n",
        "#dealing with categorical_variables\r\n",
        "ohe = OneHotEncoder()\r\n",
        "\r\n",
        "signup_method_ohe = ohe.fit_transform(train_test['signup_method'].values.reshape(-1,1)).toarray()\r\n",
        "gender_ohe = ohe.fit_transform(train_test['gender'].values.reshape(-1,1)).toarray()\r\n",
        "language_ohe = ohe.fit_transform(train_test['language'].values.reshape(-1,1)).toarray()\r\n",
        "affiliate_channel_ohe = ohe.fit_transform(train_test['affiliate_channel'].values.reshape(-1,1)).toarray()\r\n",
        "affiliate_provider_ohe = ohe.fit_transform(train_test['affiliate_provider'].values.reshape(-1,1)).toarray()\r\n",
        "first_affiliate_tracked_ohe = ohe.fit_transform(train_test['first_affiliate_tracked'].values.reshape(-1,1)).toarray()\r\n",
        "signup_app_ohe = ohe.fit_transform(train_test['signup_app'].values.reshape(-1,1)).toarray()\r\n",
        "first_device_type_ohe = ohe.fit_transform(train_test['first_device_type'].values.reshape(-1,1)).toarray()\r\n",
        "first_browser_ohe = ohe.fit_transform(train_test['first_browser'].values.reshape(-1,1)).toarray()\r\n",
        "\r\n",
        "#Getting teh labels for Target Classs\r\n",
        "le = LabelEncoder()\r\n",
        "y = le.fit_transform(train_users['country_destination'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USYNOzk9N4Te"
      },
      "source": [
        "#Now Just Combining All the Independent Features and for modeling\r\n",
        "train_test_values = np.concatenate((signup_method_ohe, gender_ohe, language_ohe, affiliate_channel_ohe,\r\n",
        "                     affiliate_provider_ohe, first_affiliate_tracked_ohe, signup_app_ohe,\r\n",
        "                    first_device_type_ohe, first_browser_ohe, train_test['dac_day'].values.reshape(-1, 1),\r\n",
        "                    train_test['dac_month'].values.reshape(-1, 1), train_test['dac_year'].values.reshape(-1, 1),\r\n",
        "                    train_test['signup_flow'].values.reshape(-1, 1), train_test['age'].values.reshape(-1, 1)),\r\n",
        "                    axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjuXqiKhWT65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b3ce9c-a9cc-4769-92e0-b369f7f7d818"
      },
      "source": [
        "#Her we're just splitting our training and test datapoints\r\n",
        "X = train_test_values[:train_users.shape[0]]\r\n",
        "X_test_final = train_test_values[train_users.shape[0]:]\r\n",
        "X.shape, y.shape, X_test_final.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((213451, 138), (213451,), (62096, 138))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIS_oK6vThAW"
      },
      "source": [
        "### NDCG Score Calculation : \r\n",
        "I have taken below function [NDCG Scorer](https://www.kaggle.com/davidgasquez/ndcg-scorer) Kaggle Kernel, **I am not sure if i can use this function in my Notebook, for now i just used it, please guide me if i need to write such Function myself?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg0I7L3wThAs"
      },
      "source": [
        "\"\"\"Metrics to compute the model performance.\"\"\"\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.metrics import make_scorer\r\n",
        "\r\n",
        "\r\n",
        "def dcg_score(y_true, y_score, k=5):\r\n",
        "    \"\"\"Discounted cumulative gain (DCG) at rank K.\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    y_true : array, shape = [n_samples]\r\n",
        "        Ground truth (true relevance labels).\r\n",
        "    y_score : array, shape = [n_samples, n_classes]\r\n",
        "        Predicted scores.\r\n",
        "    k : int\r\n",
        "        Rank.\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    score : float\r\n",
        "    \"\"\"\r\n",
        "    order = np.argsort(y_score)[::-1]\r\n",
        "    y_true = np.take(y_true, order[:k])\r\n",
        "\r\n",
        "    gain = 2 ** y_true - 1\r\n",
        "\r\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\r\n",
        "    return np.sum(gain / discounts)\r\n",
        "\r\n",
        "\r\n",
        "def ndcg_score(ground_truth, predictions, k=5):\r\n",
        "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\r\n",
        "\r\n",
        "    Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\r\n",
        "    recommendation system based on the graded relevance of the recommended\r\n",
        "    entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\r\n",
        "    ranking of the entities.\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    ground_truth : array, shape = [n_samples]\r\n",
        "        Ground truth (true labels represended as integers).\r\n",
        "    predictions : array, shape = [n_samples, n_classes]\r\n",
        "        Predicted probabilities.\r\n",
        "    k : int\r\n",
        "        Rank.\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    score : float\r\n",
        "\r\n",
        "    Example\r\n",
        "    -------\r\n",
        "    >>> ground_truth = [1, 0, 2]\r\n",
        "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\r\n",
        "    >>> score = ndcg_score(ground_truth, predictions, k=2)\r\n",
        "    1.0\r\n",
        "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\r\n",
        "    >>> score = ndcg_score(ground_truth, predictions, k=2)\r\n",
        "    0.6666666666\r\n",
        "    \"\"\"\r\n",
        "    lb = LabelBinarizer()\r\n",
        "    lb.fit(range(len(predictions) + 1))\r\n",
        "    T = lb.transform(ground_truth)\r\n",
        "\r\n",
        "    scores = []\r\n",
        "\r\n",
        "    # Iterate over each y_true and compute the DCG score\r\n",
        "    for y_true, y_score in zip(T, predictions):\r\n",
        "        actual = dcg_score(y_true, y_score, k)\r\n",
        "        best = dcg_score(y_true, y_true, k)\r\n",
        "        score = float(actual) / float(best)\r\n",
        "        scores.append(score)\r\n",
        "\r\n",
        "    return np.mean(scores)\r\n",
        "\r\n",
        "\r\n",
        "# NDCG Scorer function\r\n",
        "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwfP_UkPd8oV"
      },
      "source": [
        "## Stacking Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_iRr2XUx8EZ"
      },
      "source": [
        "\"\"\"Metrics to compute the model performance.\"\"\"\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.metrics import make_scorer\r\n",
        "\r\n",
        "\r\n",
        "def dcg_score(y_true, y_score, k=5):\r\n",
        "    \"\"\"Discounted cumulative gain (DCG) at rank K.\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    y_true : array, shape = [n_samples]\r\n",
        "        Ground truth (true relevance labels).\r\n",
        "    y_score : array, shape = [n_samples, n_classes]\r\n",
        "        Predicted scores.\r\n",
        "    k : int\r\n",
        "        Rank.\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    score : float\r\n",
        "    \"\"\"\r\n",
        "    order = np.argsort(y_score)[::-1]\r\n",
        "    y_true = np.take(y_true, order[:k])\r\n",
        "\r\n",
        "    gain = 2 ** y_true - 1\r\n",
        "\r\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\r\n",
        "    return np.sum(gain / discounts)\r\n",
        "\r\n",
        "\r\n",
        "def ndcg_score(ground_truth, predictions, k=5):\r\n",
        "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\r\n",
        "\r\n",
        "    Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\r\n",
        "    recommendation system based on the graded relevance of the recommended\r\n",
        "    entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\r\n",
        "    ranking of the entities.\r\n",
        "\r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    ground_truth : array, shape = [n_samples]\r\n",
        "        Ground truth (true labels represended as integers).\r\n",
        "    predictions : array, shape = [n_samples, n_classes]\r\n",
        "        Predicted probabilities.\r\n",
        "    k : int\r\n",
        "        Rank.\r\n",
        "\r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    score : float\r\n",
        "\r\n",
        "    Example\r\n",
        "    -------\r\n",
        "    >>> ground_truth = [1, 0, 2]\r\n",
        "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\r\n",
        "    >>> score = ndcg_score(ground_truth, predictions, k=2)\r\n",
        "    1.0\r\n",
        "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\r\n",
        "    >>> score = ndcg_score(ground_truth, predictions, k=2)\r\n",
        "    0.6666666666\r\n",
        "    \"\"\"\r\n",
        "    lb = LabelBinarizer()\r\n",
        "    lb.fit(range(len(predictions) + 1))\r\n",
        "    T = lb.transform(ground_truth)\r\n",
        "\r\n",
        "    scores = []\r\n",
        "\r\n",
        "    # Iterate over each y_true and compute the DCG score\r\n",
        "    for y_true, y_score in zip(T, predictions):\r\n",
        "        actual = dcg_score(y_true, y_score, k)\r\n",
        "        best = dcg_score(y_true, y_true, k)\r\n",
        "        score = float(actual) / float(best)\r\n",
        "        scores.append(score)\r\n",
        "\r\n",
        "    return np.mean(scores)\r\n",
        "\r\n",
        "\r\n",
        "# NDCG Scorer function\r\n",
        "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR8xvYsdxmir"
      },
      "source": [
        "!cp \"/content/drive/My Drive/Study/Case Study 1/airbnb_data/X.csv\" /content/\r\n",
        "!cp \"/content/drive/My Drive/Study/Case Study 1/airbnb_data/y.csv\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-u-oO-mxjm8"
      },
      "source": [
        "X = np.array(pd.read_csv('X.csv'))\r\n",
        "y = np.array(pd.read_csv('y.csv')).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RpphJhRkk84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a062eff-7ffe-4246-f184-e2b1a994f099"
      },
      "source": [
        "# First splitting our training data into 80-20 train and test respectively\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state = 10, stratify = y)\r\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\r\n",
        "\r\n",
        "#Now let's divide our dataset into 2 equal parts 50 - 50\r\n",
        "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(X_train, y_train , test_size = 0.5, random_state = 10, stratify = y_train)\r\n",
        "print(X_train_50.shape, y_train_50.shape, X_test_50.shape, y_test_50.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(170760, 138) (170760,) (42691, 138) (42691,)\n",
            "(85380, 138) (85380,) (85380, 138) (85380,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4TtdHU9383G"
      },
      "source": [
        "''' Approach : I will work on X_train_50 and y_train_50, \r\n",
        "    from this dataset i will be creating 10 datasets with sampling with replacement.\r\n",
        "    Now i will train 10 models on each of these datasets, and will predict on X_test_50\r\n",
        "    will all these 10 model, now i will be having 10 columns of predictions of each Model and i will make the dataset of \r\n",
        "    these predictions and y_test_50 as target variable. and this model will be my meta classifier or final model. '''\r\n",
        "\r\n",
        "#\"random_samples_generator\" this function basically generates the indexes of raondom samples with replacement\r\n",
        "def random_samples_generator():\r\n",
        "    \"\"\" \r\n",
        "    Generating 60 % Unique Indexes of our total data, \r\n",
        "    and in next step we will generate 40% of Indexes of our total data, from this 60% indexes\r\n",
        "    with replacement.\r\n",
        "    \"Its Your Choice, weather you wanna take first 60% Unique data points or not\", \r\n",
        "    you can take all data with duplicate data points if you want.    \r\n",
        "    \r\n",
        "    \"\"\"   \r\n",
        "    #Below two lines of code performs row sampling\r\n",
        "    X_sample_indexes = np.random.choice(np.arange(len(X_train_50)), \r\n",
        "                                        size = int(len(X_train_50)/100 * 60), replace = False)\r\n",
        "\r\n",
        "    #Generating 40% Indexes from above 60% of Indexes with duplicate indexes\r\n",
        "    X_sample_indexes = np.append(X_sample_indexes, np.random.choice(X_sample_indexes, \r\n",
        "                                size = int(len(X_train_50)/100 * 60)))\r\n",
        "    \r\n",
        "    #Below lines of code is used for column sampling\r\n",
        "    #Now Generating a Random Variable between 80(included) and 139(excluded)\r\n",
        "    #Which is basically Number Columns We are gonna take for current Sample\r\n",
        "    random_columns = np.random.randint(80, 139)\r\n",
        "\r\n",
        "    #Now Column Sampling is being done\r\n",
        "    sample_columns = np.random.choice(np.arange(138), size = random_columns, replace = False)\r\n",
        "\r\n",
        "    return X_sample_indexes, sample_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjP8AmMsk4rF"
      },
      "source": [
        "### Decision Tree - Base Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqIOAHfWruve"
      },
      "source": [
        "#Below dataframe is to hold the predictions made by base learners, later we will use these prediction to train meta model\r\n",
        "base_model_pred = pd.DataFrame()\r\n",
        "\r\n",
        "#Below dataframe is to hold the columns on which base maodel is trained, we will be needing these column while predicting on test data\r\n",
        "base_model_cols = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IccIahknk1Q6",
        "outputId": "fc2b435b-fb63-4e62-bfcf-a4c585d2d3e8"
      },
      "source": [
        "#Here we're using GridSearchCv to find the best hyper parameter\r\n",
        "parameters = {'max_depth': [3, 5, 7 , 9, 13]}\r\n",
        "clf_decision_tree = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = parameters, \r\n",
        "                   cv = KFold(n_splits = 5, shuffle = True, random_state= 134), n_jobs = -1, \r\n",
        "                   scoring = ndcg_scorer)\r\n",
        "\r\n",
        "#Calling the random_sample_generator for row and column sampling indexes\r\n",
        "sample_index, sample_columns =  random_samples_generator()\r\n",
        "\r\n",
        "clf_decision_tree.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "print(clf_decision_tree.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P3qu5Cj0Sgg"
      },
      "source": [
        "#Joining column with comma and storing in dataframe\r\n",
        "base_model_cols['decision_tree'] = [\",\".join([str(x) for x in sample_columns])]\r\n",
        "base_model_cols.to_csv('base_model_cols.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBrfTdBak1NZ"
      },
      "source": [
        "#Now When we have our best hyper paramter let's train our model and predicting\r\n",
        "clf = DecisionTreeClassifier(max_depth=clf_decision_tree.best_params_['max_depth'])\r\n",
        "clf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "y_preds = clf.predict(X_test_50[:, sample_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5igpUYkyk1KW"
      },
      "source": [
        "#Saving the predictions in dataframe for later use\r\n",
        "base_model_pred['decision_tree'] = y_preds\r\n",
        "base_model_pred.to_csv('base_model_preds.csv', index = False)\r\n",
        "\r\n",
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('decision_tree.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTbMCU_Tyrsg"
      },
      "source": [
        "### Random Forest - Base Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klW2Z-ejuG_e"
      },
      "source": [
        "#Below dataframe is to hold the predictions made by base learners, later we will use these prediction to train meta model\r\n",
        "base_model_pred = pd.DataFrame()\r\n",
        "\r\n",
        "#Below dataframe is to hold the columns on which base maodel is trained, we will be needing these column while predicting on test data\r\n",
        "base_model_cols = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAy6Q0gByyzD",
        "outputId": "ce23c0b3-2ad7-4bc8-d9c9-072c94ea5b01"
      },
      "source": [
        "#Here we're using GridSearchCv to find the best hyper parameter\r\n",
        "parameters = [{'n_estimators': [5,10, 50, 100, 150, 200], 'max_depth': [3, 7, 11, 15, 19]}]\r\n",
        "clf_rf = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameters, \r\n",
        "                   cv = KFold(n_splits = 5, shuffle = True, random_state= 134), n_jobs = -1, \r\n",
        "                   scoring = ndcg_scorer)\r\n",
        "\r\n",
        "#Calling the random_sample_generator for row and column sampling indexes\r\n",
        "sample_index, sample_columns =  random_samples_generator()\r\n",
        "clf_rf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "print(clf_rf.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 19, 'n_estimators': 200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALUr_9G74idn"
      },
      "source": [
        "#Joining column with comma and storing in dataframe\r\n",
        "base_model_cols['random_forest'] = [\",\".join([str(x) for x in sample_columns])]\r\n",
        "base_model_cols.to_csv('base_model_cols.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kMVdm9ayyzs"
      },
      "source": [
        "#Now When we have our best hyper paramter let's train our model and predicting\r\n",
        "clf = RandomForestClassifier(max_depth=clf_rf.best_params_['max_depth'], n_estimators=clf_rf.best_params_['n_estimators'])\r\n",
        "clf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "y_preds = clf.predict(X_test_50[:, sample_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj-WYtYTyyzz"
      },
      "source": [
        "#Saving the predictions in dataframe for later use\r\n",
        "base_model_pred['random_forest'] = y_preds\r\n",
        "base_model_pred.to_csv('base_model_preds.csv', index = False)\r\n",
        "\r\n",
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('random_forest.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AS-nhp51ILt"
      },
      "source": [
        "### ExtraTreeClassifier - Base Learner\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roF82sv7uSUL"
      },
      "source": [
        "#Below dataframe is to hold the predictions made by base learners, later we will use these prediction to train meta model\r\n",
        "base_model_pred = pd.DataFrame()\r\n",
        "\r\n",
        "#Below dataframe is to hold the columns on which base maodel is trained, we will be needing these column while predicting on test data\r\n",
        "base_model_cols = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmrZT6q41UpO",
        "outputId": "d879044d-38ba-4dcd-884d-14dece48af22"
      },
      "source": [
        "#Here we're using GridSearchCv to find the best hyper parameter\r\n",
        "parameters = [{'n_estimators': [5,10, 50, 100, 150], 'max_depth': [3, 7, 11, 15, 19]}]\r\n",
        "clf_etc = GridSearchCV(estimator = ExtraTreesClassifier(), param_grid = parameters, \r\n",
        "                   cv = KFold(n_splits = 5, shuffle = True, random_state= 134), n_jobs = -1, \r\n",
        "                   scoring = ndcg_scorer)\r\n",
        "\r\n",
        "#Calling the random_sample_generator for row and column sampling indexes\r\n",
        "sample_index, sample_columns =  random_samples_generator()\r\n",
        "clf_etc.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "print(clf_etc.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 19, 'n_estimators': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lag52eHd4wtt"
      },
      "source": [
        "#Joining column with comma and storing in dataframe\r\n",
        "base_model_cols['extra_tree'] = [\",\".join([str(x) for x in sample_columns])]\r\n",
        "base_model_cols.to_csv('base_model_cols.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oyBR2Dv1UpR"
      },
      "source": [
        "#Now When we have our best hyper paramter let's train our model and predicting\r\n",
        "clf = ExtraTreesClassifier(max_depth=clf_etc.best_params_['max_depth'], n_estimators=clf_etc.best_params_['n_estimators'])\r\n",
        "clf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "y_preds = clf.predict(X_test_50[:, sample_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NAw1uQ91UpS"
      },
      "source": [
        "#Saving the predictions in dataframe for later use\r\n",
        "base_model_pred['extra_tree'] = y_preds\r\n",
        "base_model_pred.to_csv('base_model_preds.csv', index = False)\r\n",
        "\r\n",
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('extra_tree.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIEDBP9P1kzu"
      },
      "source": [
        "### KNeighbors - Base Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGhNLWZCul5l"
      },
      "source": [
        "#Below dataframe is to hold the predictions made by base learners, later we will use these prediction to train meta model\r\n",
        "base_model_pred = pd.DataFrame()\r\n",
        "\r\n",
        "#Below dataframe is to hold the columns on which base maodel is trained, we will be needing these column while predicting on test data\r\n",
        "base_model_cols = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G96efr62QSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4a4678-1d63-4cde-938a-1d2e20729c36"
      },
      "source": [
        "#Here we're using GridSearchCv to find the best hyper parameter\r\n",
        "parameters = [{'n_neighbors': [3, 5, 7, 9, 13 ] }]\r\n",
        "clf_knn = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = parameters, \r\n",
        "                   cv = KFold(n_splits = 5, shuffle = True, random_state= 134), n_jobs = -1, \r\n",
        "                   scoring = ndcg_scorer)\r\n",
        "\r\n",
        "#Calling the random_sample_generator for row and column sampling indexes\r\n",
        "sample_index, sample_columns =  random_samples_generator()\r\n",
        "clf_knn.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "print(clf_knn.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_neighbors': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMe2boSq4z0x"
      },
      "source": [
        "#Joining column with comma and storing in dataframe\r\n",
        "base_model_cols['knn'] = [\",\".join([str(x) for x in sample_columns])]\r\n",
        "base_model_cols.to_csv('base_model_cols.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHgKfGeH2QS7"
      },
      "source": [
        "#Now When we have our best hyper paramter let's train our model and predicting\r\n",
        "clf = KNeighborsClassifier(n_neighbors=clf_knn.best_params_['n_neighbors'])\r\n",
        "clf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "y_preds = clf.predict(X_test_50[:, sample_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXWaj8Yi2QS8"
      },
      "source": [
        "#Saving the predictions in dataframe for later use\r\n",
        "base_model_pred['knn'] = y_preds\r\n",
        "base_model_pred.to_csv('base_model_preds.csv', index = False)\r\n",
        "\r\n",
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('knn.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxCrRysV1o2-"
      },
      "source": [
        "### Naive Bayes - Base Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CToP59Vuuwtn"
      },
      "source": [
        "#Below dataframe is to hold the predictions made by base learners, later we will use these prediction to train meta model\r\n",
        "base_model_pred = pd.DataFrame()\r\n",
        "\r\n",
        "#Below dataframe is to hold the columns on which base maodel is trained, we will be needing these column while predicting on test data\r\n",
        "base_model_cols = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrBjxDoI2Rna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd5ede2-0342-448b-c7fc-2be0b10e4319"
      },
      "source": [
        "#Here we're using GridSearchCv to find the best hyper parameter\r\n",
        "parameters = {'alpha': [10, 100, 150, 200, 300, 400, 500]}\r\n",
        "clf_nb = GridSearchCV(estimator = BernoulliNB(), param_grid = parameters, \r\n",
        "                   cv = KFold(n_splits = 5, shuffle = True, random_state= 134), n_jobs = -1, \r\n",
        "                   scoring = ndcg_scorer)\r\n",
        "\r\n",
        "#Calling the random_sample_generator for row and column sampling indexes\r\n",
        "sample_index, sample_columns =  random_samples_generator()\r\n",
        "clf_nb.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "print(clf_nb.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 150}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78mWxerC44oS"
      },
      "source": [
        "#Joining column with comma and storing in dataframe\r\n",
        "base_model_cols['naive_bayes'] = [\",\".join([str(x) for x in sample_columns])]\r\n",
        "base_model_cols.to_csv('base_model_cols.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T9xNwpV2Rna"
      },
      "source": [
        "#Now When we have our best hyper paramter let's train our model and predicting\r\n",
        "clf = BernoulliNB(alpha=clf_nb.best_params_['alpha'],)\r\n",
        "clf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "y_preds = clf.predict(X_test_50[:, sample_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZKnm1Ki2Rnb"
      },
      "source": [
        "#Saving the predictions in dataframe for later use\r\n",
        "base_model_pred['naive_bayes'] = y_preds\r\n",
        "base_model_pred.to_csv('base_model_preds.csv', index = False)\r\n",
        "\r\n",
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('naive_bayes.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQrwAvlI1_YH"
      },
      "source": [
        "### Logistic Regression - Base Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c66dFpUvRnI"
      },
      "source": [
        "#Below dataframe is to hold the predictions made by base learners, later we will use these prediction to train meta model\r\n",
        "base_model_pred = pd.DataFrame()\r\n",
        "\r\n",
        "#Below dataframe is to hold the columns on which base maodel is trained, we will be needing these column while predicting on test data\r\n",
        "base_model_cols = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajuZYwsg2Vt3"
      },
      "source": [
        "#Training the model\r\n",
        "sample_index, sample_columns =  random_samples_generator()\r\n",
        "clf_rf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKhJUI3t2Vt4"
      },
      "source": [
        "#Now When we have our best hyper paramter let's train our model and predicting\r\n",
        "clf = LogisticRegression( multi_class='multinomial', max_iter=10000, C=0.1)\r\n",
        "clf.fit(X_train_50[sample_index][:, sample_columns], y_train_50[sample_index])\r\n",
        "y_preds = clf.predict(X_test_50[:, sample_columns])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRpo18_SvNiG"
      },
      "source": [
        "#Joining column with comma and storing in dataframe\r\n",
        "base_model_cols['log_reg'] = [\",\".join([str(x) for x in sample_columns])]\r\n",
        "base_model_cols.to_csv('base_model_cols.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIYWNAY12Vt5"
      },
      "source": [
        "#Saving the predictions in dataframe for later use\r\n",
        "base_model_pred['log_reg'] = y_preds\r\n",
        "base_model_pred.to_csv('base_model_preds.csv', index = False)\r\n",
        "\r\n",
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('log_reg.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUVzyFnr1auG"
      },
      "source": [
        "### Meta Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpBVSi1I17Jh"
      },
      "source": [
        "base_model_preds = pd.read_csv('/content/drive/MyDrive/Study/Case Study 1/Saved_Models/base_model_preds.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPiymzHY17QL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ecea52-7945-4a84-b94f-214d2be2d168"
      },
      "source": [
        "#For the Meta Classifier we will be using XGBClassifier, and will be using GridSearchCv for Hyper parameter tuning\r\n",
        "parameters = [{'n_estimators': [50, 100, 150, 200], 'max_depth': [3, 7, 11, 15, 19]}]\r\n",
        "clf_meta = GridSearchCV(estimator = xgb.XGBClassifier(), param_grid = parameters, \r\n",
        "                   cv = KFold(n_splits = 5, shuffle = True, random_state= 134), \r\n",
        "                   scoring = ndcg_scorer)\r\n",
        "\r\n",
        "#let's fit our metaclassifer on predicted values of base classifiers and predict the values \r\n",
        "clf_meta.fit(np.array(base_model_preds), y_test_50)\r\n",
        "clf_meta.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 3, 'n_estimators': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIEqPsUx173x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70b96aa-fe8b-4e25-890d-20e64d4514ef"
      },
      "source": [
        "#Now When we have our best hyper paramter let's train our model and predicting\r\n",
        "clf = xgb.XGBClassifier(max_depth=clf_meta.best_params_['max_depth'], n_estimators=clf_meta.best_params_['n_estimators'])\r\n",
        "clf.fit(np.array(base_model_preds), y_test_50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=50, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5SFV-ap170H"
      },
      "source": [
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('meta_xgb.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPsJoL0k17wo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zTo8aII17U2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht2q_VqYI0K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16263af3-187b-45a5-c00b-930d847c7020"
      },
      "source": [
        "#For the Meta Classifier we will be using RandomForestClassifier, and will be using GridSearchCv for Hyper parameter tuning\r\n",
        "parameters = [{'n_estimators': [50, 100, 150, 200], 'max_depth': [3, 7, 11, 15, 19]}]\r\n",
        "clf_meta = GridSearchCV(estimator = RandomForestClassifier(), param_grid = parameters, \r\n",
        "                   cv = KFold(n_splits = 5, shuffle = True, random_state= 134), \r\n",
        "                   scoring = ndcg_scorer)\r\n",
        "\r\n",
        "#let's fit our metaclassifer on predicted values of base classifiers and predict the values \r\n",
        "clf_meta.fit(np.array(base_model_pred), y_test_50)\r\n",
        "clf_meta.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 7, 'n_estimators': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baCU4an7AaRR"
      },
      "source": [
        "#Now, when we have our best hyperparameters let's train our meta model\r\n",
        "clf = RandomForestClassifier(max_depth = 7, n_estimators = 200).fit(np.array(base_model_pred), y_test_50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqJuZ-2yA-Nn"
      },
      "source": [
        "#Prediction on Final Test Data\r\n",
        "#Now We are creating one dataframe of prediction of each model on our final testing dataset\r\n",
        "base_model_pred_test = pd.DataFrame()\r\n",
        "for model_name, model in model_dict.items():\r\n",
        "    base_model_pred_test[model_name] = model_dict[model_name][0].predict(X_test_final[:, model_dict[model_name][2]])\r\n",
        "\r\n",
        "y_preds = clf.predict_proba(np.array(base_model_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeP34IhIH5YY"
      },
      "source": [
        "'''This Code is basically used get top 5 predictions for the submission file\r\n",
        "   Here we're just zipping predictions and classes together and sorting with predictions,\r\n",
        "   and then taking top5 countries, that's it.'''\r\n",
        "\r\n",
        "prediction_classes = le.classes_\r\n",
        "user_list = []\r\n",
        "predictions_list = []\r\n",
        "for user_index in range(len(test_users)):\r\n",
        "    user_list.extend([test_users['id'][user_index]] * 5)\r\n",
        "    sorted_values = sorted(zip(y_preds[user_index], prediction_classes), reverse = True)[:5]\r\n",
        "    predictions_list.extend([country[1] for country in sorted_values])\r\n",
        "    \r\n",
        "submission_file = pd.DataFrame({'id':user_list, 'country':predictions_list})\r\n",
        "submission_file.to_csv('submission_stacking_3.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1xw0hPACEs3"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ0z2R7ICoiP"
      },
      "source": [
        "#Saving Models\r\n",
        "for model_name, model in model_dict.items():\r\n",
        "    pickle.dump(model, open(model_name, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BIvE3k8r5Vp"
      },
      "source": [
        "#Saving the model for later use\r\n",
        "pickle.dump(clf, open('rfc_stacking_86393.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9MhbyK6CfTx"
      },
      "source": [
        "model1 = pickle.load(open('model1', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dbGFUeaDTiK",
        "outputId": "227451f5-8072-44c3-b2b5-95dc1bbe3c4e"
      },
      "source": [
        "model1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=124, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9I1sB0PDY4v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}